{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus is latin for 'body', plural is Corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Corpora /Text Corpus \n",
    "\n",
    "- Gutenberg Corpus\n",
    "- Web and Chat Text\n",
    "- Brown Corpus \n",
    "- Reuters Corpus\n",
    "- Inaugural Address Corpus\n",
    "- Annotated Text Corpora\n",
    "\n",
    "```python\n",
    ">>> nltk.download('punkt')\n",
    ">>> nltk.download('book')\n",
    "```\n",
    "will be downloaded in the user directory\n",
    "\n",
    "\n",
    "#### Gutenberg Corpus \n",
    "NLTK includes a small selection of texts from the Project Gutenberg electronic text archive, which contains some 25,000 free electronic books, hosted at. \n",
    "    \n",
    "<a href='http://www.gutenberg.org/'>http://www.gutenberg.org/</a>\n",
    "\n",
    "#### Brown \n",
    "The Brown Corpus was the first million-word electronic corpus of English, \n",
    "    \n",
    "#### Inaugural \n",
    "US presidential speeches \n",
    "    \n",
    "    \n",
    "#### Popular Text Corpora \n",
    "\n",
    "stopwords : Collection of stop words.\n",
    "reuters : Collection of news articles.\n",
    "cmudict : Collection of CMU Dictionary words.\n",
    "movie_reviews : Collection of Movie Reviews.\n",
    "np_chat : Collection of chat text.\n",
    "names : Collection of names associated with males and females.\n",
    "state_union : Collection of state union address.\n",
    "wordnet : Collection of all lexical entries.\n",
    "words : Collection of words in Wordlist corpus.\n",
    "\n",
    "#### Text Corpus Structure\n",
    "A text corpus is organized into any of the following four structures.\n",
    "\n",
    "Isolated - Holds Individual text collections.\n",
    "Categorized - Each text collection tagged to a category.\n",
    "Overlapping - Each text collection tagged to one or more categories, and\n",
    "Temporal - Each text collection tagged to a period, date, time, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['english-kjv.txt',\n",
       " 'english-web.txt',\n",
       " 'finnish.txt',\n",
       " 'french.txt',\n",
       " 'german.txt',\n",
       " 'lolcat.txt',\n",
       " 'portuguese.txt',\n",
       " 'swedish.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import genesis \n",
    "\n",
    "genesis.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------------+-----------------+\n",
      "| average word length | average sentence length |     fileids     |\n",
      "+---------------------+-------------------------+-----------------+\n",
      "|          4          |            30           | english-kjv.txt |\n",
      "|          4          |            19           | english-web.txt |\n",
      "|          5          |            15           |   finnish.txt   |\n",
      "|          4          |            23           |    french.txt   |\n",
      "|          4          |            23           |    german.txt   |\n",
      "|          4          |            20           |    lolcat.txt   |\n",
      "|          4          |            27           |  portuguese.txt |\n",
      "|          4          |            30           |   swedish.txt   |\n",
      "+---------------------+-------------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"average word length\",\"average sentence length\",\"fileids\"]\n",
    "for fileid in genesis.fileids():\n",
    "    n_chars = len(genesis.raw(fileid))\n",
    "    n_words = len(genesis.words(fileid))\n",
    "    n_sents = len(genesis.sents(fileid))\n",
    "    \n",
    "    \n",
    "    x.add_row([int(n_chars/n_words), int(n_words/n_sents), fileid])\n",
    "    \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import inaugural\n",
    "int(len(inaugural.words('1789-Washington.txt')) / len(set(inaugural.words('1789-Washington.txt'))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python383jvsc74a57bd0dba788e4a50ad11c3aca04f6a487ccbbf2decea49c956f88ab099965f16291a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
